{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4da5ef-1ed4-4a83-ab91-e0fd86f3140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeee6a27-1383-47df-9e4a-9456f589ce8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Train set: (19524, 12, 32), (19524,)\n",
      "Validation set: (2441, 12, 32), (2441,)\n",
      "Test set: (2440, 12, 32), (2440,)\n"
     ]
    }
   ],
   "source": [
    "# Enable mixed precision and XLA JIT compilation\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# Load data (use smaller sequences by downsampling for speed)\n",
    "print(\"Loading datasets...\")\n",
    "X_train = np.load('X_train.npy')[:, ::2, :]  # Downsample by 2\n",
    "y_train = np.load('y_train.npy').astype(np.int32)  # Ensure sparse labels\n",
    "X_val = np.load('X_val.npy')[:, ::2, :]\n",
    "y_val = np.load('y_val.npy').astype(np.int32)\n",
    "X_test = np.load('X_test.npy')[:, ::2, :]\n",
    "y_test = np.load('y_test.npy').astype(np.int32)\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef0c1b6-219b-45e0-81a1-a5ee23eda704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the Ultra-Light LSTM model...\n",
      "\n",
      "Compiling the model...\n",
      "\n",
      "Training the model...\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebarn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5590 - loss: 0.7549 - val_accuracy: 0.8755 - val_loss: 0.5531\n",
      "Epoch 2/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7604 - loss: 0.5484 - val_accuracy: 0.9394 - val_loss: 0.4582\n",
      "Epoch 3/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9198 - loss: 0.4191 - val_accuracy: 0.9385 - val_loss: 0.3689\n",
      "Epoch 4/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9543 - loss: 0.3135 - val_accuracy: 0.9443 - val_loss: 0.2932\n",
      "Epoch 5/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9590 - loss: 0.2429 - val_accuracy: 0.9492 - val_loss: 0.2369\n",
      "Epoch 6/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.2036 - val_accuracy: 0.9545 - val_loss: 0.1997\n",
      "Epoch 7/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9631 - loss: 0.1725 - val_accuracy: 0.9599 - val_loss: 0.1760\n",
      "Epoch 8/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9584 - loss: 0.1694 - val_accuracy: 0.9615 - val_loss: 0.1614\n",
      "Epoch 9/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9637 - loss: 0.1506 - val_accuracy: 0.9619 - val_loss: 0.1525\n",
      "Epoch 10/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9637 - loss: 0.1483 - val_accuracy: 0.9623 - val_loss: 0.1458\n",
      "Epoch 11/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9635 - loss: 0.1444 - val_accuracy: 0.9619 - val_loss: 0.1428\n",
      "Epoch 12/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9632 - loss: 0.1429 - val_accuracy: 0.9623 - val_loss: 0.1412\n",
      "Epoch 13/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9637 - loss: 0.1426 - val_accuracy: 0.9635 - val_loss: 0.1400\n",
      "Epoch 14/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9662 - loss: 0.1357 - val_accuracy: 0.9631 - val_loss: 0.1391\n",
      "Epoch 15/15\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9630 - loss: 0.1424 - val_accuracy: 0.9635 - val_loss: 0.1374\n",
      "Model training completed.\n"
     ]
    }
   ],
   "source": [
    "# Build a blazing-fast, lightweight LSTM model\n",
    "print(\"\\nBuilding the Ultra-Light LSTM model...\")\n",
    "model = Sequential([\n",
    "    LSTM(1, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n",
    "    BatchNormalization(),  # Stabilizes training\n",
    "    Dense(1, activation='sigmoid', dtype='float32')  # Ensure output remains in float32\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "print(\"\\nCompiling the model...\")\n",
    "model.compile(optimizer=Adam(learning_rate=0.005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "print(\"\\nTraining the model...\")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=15,  # Extremely fast training\n",
    "    batch_size=512,  # Large batch size for speed\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ac09df-889d-4696-9d3d-0c2f9bc4a9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the trained model to 'ultra_light_lstm_model.h5'...\n",
      "Model saved successfully.\n",
      "\n",
      "Evaluating the model on test data...\n",
      "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Test data metrics computed.\n",
      "\n",
      "Final Training Loss and Validation Loss\n",
      "Final Training Loss: 0.1409, Validation Loss: 0.1374\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "print(\"\\nSaving the trained model to 'ultra_light_lstm_model.h5'...\")\n",
    "model.save('ultra_light_lstm_model.h5')\n",
    "print(\"Model saved successfully.\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"\\nEvaluating the model on test data...\")\n",
    "y_pred_test = (model.predict(X_test) > 0.5).astype(int)\n",
    "test_metrics = {\n",
    "    \"accuracy\": (y_pred_test == y_test).mean(),\n",
    "    \"precision\": precision_score(y_test, y_pred_test),\n",
    "    \"recall\": recall_score(y_test, y_pred_test),\n",
    "    \"f1_score\": f1_score(y_test, y_pred_test),\n",
    "    \"confusion_matrix\": confusion_matrix(y_test, y_pred_test).tolist(),\n",
    "}\n",
    "print(\"Test data metrics computed.\")\n",
    "\n",
    "# Summarize results\n",
    "print(\"\\nFinal Training Loss and Validation Loss\")\n",
    "final_train_loss = history.history['loss'][-1]\n",
    "final_val_loss = history.history['val_loss'][-1]\n",
    "print(f\"Final Training Loss: {final_train_loss:.4f}, Validation Loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd0123a-c75d-4152-b8ea-8843eac9aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Model Card...\n",
      "Model Card created.\n",
      "\n",
      "Saving Model Card to 'ultra_light_model_card.json'...\n",
      "Model Card saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a Model Card\n",
    "print(\"\\nCreating Model Card...\")\n",
    "model_card = {\n",
    "    \"Model Name\": \"Ultra-Lightweight LSTM\",\n",
    "    \"Version\": \"1.2\",\n",
    "    \"Model Architecture\": \"Single LSTM Unit, BatchNorm, Dense Sigmoid Output\",\n",
    "    \"Purpose\": \"Predict sepsis risk using time-series health data.\",\n",
    "    \"Dataset\": {\n",
    "        \"Train Shape\": X_train.shape,\n",
    "        \"Validation Shape\": X_val.shape,\n",
    "        \"Test Shape\": X_test.shape,\n",
    "    },\n",
    "    \"Training Configuration\": {\n",
    "        \"Epochs\": len(history.history['loss']),\n",
    "        \"Batch Size\": 512,\n",
    "        \"Optimizer\": \"Adam\",\n",
    "        \"Learning Rate\": 0.005,\n",
    "        \"Loss Function\": \"Binary Crossentropy\",\n",
    "    },\n",
    "    \"Performance Metrics (Test Data)\": test_metrics,\n",
    "    \"Limitations\": [\n",
    "        \"Simplified architecture may underperform on more complex datasets.\",\n",
    "        \"Requires further validation on diverse patient datasets.\",\n",
    "    ],\n",
    "    \"Ethical Considerations\": [\n",
    "        \"Validate predictions with human oversight.\",\n",
    "        \"Ensure fairness across patient demographics.\",\n",
    "    ],\n",
    "    \"Author\": \"Eric Barnes\",\n",
    "    \"Date\": \"2024-11-18\",\n",
    "}\n",
    "print(\"Model Card created.\")\n",
    "\n",
    "# Save the Model Card\n",
    "print(\"\\nSaving Model Card to 'ultra_light_model_card.json'...\")\n",
    "with open('ultra_light_model_card.json', 'w') as f:\n",
    "    json.dump(model_card, f, indent=4)\n",
    "print(\"Model Card saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
